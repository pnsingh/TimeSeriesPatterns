{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing VAE using Keras ## \n",
    "Links:\n",
    "\n",
    "https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "m = 50\n",
    "n_z = 2\n",
    "n_epoch = 10\n",
    "\n",
    "\n",
    "# Q(z|X) -- encoder\n",
    "inputs = Input(shape=(784,))\n",
    "h_q = Dense(512, activation='relu')(inputs)\n",
    "mu = Dense(n_z, activation='linear')(h_q)\n",
    "log_sigma = Dense(n_z, activation='linear')(h_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    eps = K.random_normal(shape=(m, n_z), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_sigma / 2) * eps\n",
    "\n",
    "\n",
    "# Sample z ~ Q(z|X)\n",
    "z = Lambda(sample_z, output_shape=(n_z,))([mu, log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P(X|z) -- decoder\n",
    "decoder_hidden = Dense(512, activation='relu')\n",
    "decoder_out = Dense(784, activation='sigmoid')\n",
    "\n",
    "h_p = decoder_hidden(z)\n",
    "outputs = decoder_out(h_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overall VAE model, for reconstruction and training\n",
    "vae = Model(inputs, outputs)\n",
    "\n",
    "# Encoder model, to encode input into latent variable\n",
    "# We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "encoder = Model(inputs, mu)\n",
    "\n",
    "# Generator model, generate new data given latent variable z\n",
    "d_in = Input(shape=(n_z,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "    # E[log P(X|z)]\n",
    "    recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "    # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "    kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "\n",
    "    return recon + kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_trainO,_),(x_testO,_)=mnist.load_data()\n",
    "x_test=x_testO.reshape(len(x_testO),np.prod(x_testO.shape[1:]))\n",
    "x_train=x_trainO.reshape(len(x_trainO),np.prod(x_trainO.shape[1:]))\n",
    "train_size=int(len(x_train)*0.8)\n",
    "valid_size=int(len(x_train)*0.2)\n",
    "\n",
    "## Normalizing the data between zero and 1 ## \n",
    "x_train=x_train.astype('float32')/255.\n",
    "x_test=x_test.astype('float32')/255.\n",
    "print x_test.shape\n",
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 182.7657Epoch 00000: val_loss improved from inf to 168.49767, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 182.7386 - val_loss: 168.4977\n",
      "Epoch 2/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 166.2936Epoch 00001: val_loss improved from 168.49767 to 164.58499, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 166.2977 - val_loss: 164.5850\n",
      "Epoch 3/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 162.9363Epoch 00002: val_loss improved from 164.58499 to 161.53673, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 162.9396 - val_loss: 161.5367\n",
      "Epoch 4/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 160.1942Epoch 00003: val_loss improved from 161.53673 to 159.36857, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 160.1890 - val_loss: 159.3686\n",
      "Epoch 5/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 158.1282Epoch 00004: val_loss improved from 159.36857 to 157.58768, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 158.1193 - val_loss: 157.5877\n",
      "Epoch 6/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 156.7367Epoch 00005: val_loss improved from 157.58768 to 156.53661, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 156.7390 - val_loss: 156.5366\n",
      "Epoch 7/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 155.6935Epoch 00006: val_loss improved from 156.53661 to 155.59469, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 155.6931 - val_loss: 155.5947\n",
      "Epoch 8/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 154.8618Epoch 00007: val_loss improved from 155.59469 to 155.01834, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 154.8645 - val_loss: 155.0183\n",
      "Epoch 9/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 154.1968Epoch 00008: val_loss improved from 155.01834 to 154.36150, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 154.2003 - val_loss: 154.3615\n",
      "Epoch 10/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 153.5769Epoch 00009: val_loss improved from 154.36150 to 153.86229, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 153.5762 - val_loss: 153.8623\n",
      "Epoch 11/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 153.0816Epoch 00010: val_loss improved from 153.86229 to 153.85239, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 153.0823 - val_loss: 153.8524\n",
      "Epoch 12/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 152.6074Epoch 00011: val_loss improved from 153.85239 to 153.80264, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 152.6156 - val_loss: 153.8026\n",
      "Epoch 13/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 152.2378Epoch 00012: val_loss improved from 153.80264 to 152.86577, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 152.2469 - val_loss: 152.8658\n",
      "Epoch 14/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 151.8889Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 151.8747 - val_loss: 152.9080\n",
      "Epoch 15/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 151.5305Epoch 00014: val_loss improved from 152.86577 to 152.45032, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 151.5343 - val_loss: 152.4503\n",
      "Epoch 16/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 151.1659Epoch 00015: val_loss improved from 152.45032 to 152.05611, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 151.1722 - val_loss: 152.0561\n",
      "Epoch 17/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 150.8534Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 150.8662 - val_loss: 152.0877\n",
      "Epoch 18/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 150.6005Epoch 00017: val_loss improved from 152.05611 to 151.68687, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 150.6028 - val_loss: 151.6869\n",
      "Epoch 19/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 150.2885Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 150.2886 - val_loss: 151.8769\n",
      "Epoch 20/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 150.0616Epoch 00019: val_loss improved from 151.68687 to 151.36424, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 150.0628 - val_loss: 151.3642\n",
      "Epoch 21/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 149.8930Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 149.8792 - val_loss: 151.4268\n",
      "Epoch 22/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 149.5825Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 149.5876 - val_loss: 151.5440\n",
      "Epoch 23/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 149.4402Epoch 00022: val_loss improved from 151.36424 to 151.14999, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 149.4383 - val_loss: 151.1500\n",
      "Epoch 24/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 149.2163Epoch 00023: val_loss improved from 151.14999 to 151.05499, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 149.2178 - val_loss: 151.0550\n",
      "Epoch 25/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 149.0793Epoch 00024: val_loss improved from 151.05499 to 150.87168, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 149.0619 - val_loss: 150.8717\n",
      "Epoch 26/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 148.8355Epoch 00025: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 148.8355 - val_loss: 151.1010\n",
      "Epoch 27/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 148.7236Epoch 00026: val_loss improved from 150.87168 to 150.75888, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 18s - loss: 148.7190 - val_loss: 150.7589\n",
      "Epoch 28/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 148.5416Epoch 00027: val_loss did not improve\n",
      "60000/60000 [==============================] - 19s - loss: 148.5565 - val_loss: 150.9389\n",
      "Epoch 29/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 148.3843Epoch 00028: val_loss improved from 150.75888 to 150.56289, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 18s - loss: 148.3951 - val_loss: 150.5629\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59950/60000 [============================>.] - ETA: 0s - loss: 148.2598Epoch 00029: val_loss improved from 150.56289 to 150.42623, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 148.2581 - val_loss: 150.4262\n",
      "Epoch 31/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 148.1371Epoch 00030: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 148.1343 - val_loss: 150.5153\n",
      "Epoch 32/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 147.9990Epoch 00031: val_loss improved from 150.42623 to 150.32021, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 148.0018 - val_loss: 150.3202\n",
      "Epoch 33/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 147.8579Epoch 00032: val_loss improved from 150.32021 to 150.21800, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 147.8469 - val_loss: 150.2180\n",
      "Epoch 34/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 147.7374Epoch 00033: val_loss improved from 150.21800 to 150.12145, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 147.7337 - val_loss: 150.1214\n",
      "Epoch 35/50\n",
      "59750/60000 [============================>.] - ETA: 0s - loss: 147.6379Epoch 00034: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 147.6349 - val_loss: 150.2298\n",
      "Epoch 36/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 147.5192Epoch 00035: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 147.5095 - val_loss: 150.2918\n",
      "Epoch 37/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 147.3813Epoch 00036: val_loss improved from 150.12145 to 149.84735, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 147.3797 - val_loss: 149.8474\n",
      "Epoch 38/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 147.2756Epoch 00037: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 147.2788 - val_loss: 149.9439\n",
      "Epoch 39/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 147.1163Epoch 00038: val_loss improved from 149.84735 to 149.71289, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 147.1371 - val_loss: 149.7129\n",
      "Epoch 40/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 147.0430Epoch 00039: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 147.0387 - val_loss: 149.7783\n",
      "Epoch 41/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 146.9632Epoch 00040: val_loss improved from 149.71289 to 149.61108, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 146.9615 - val_loss: 149.6111\n",
      "Epoch 42/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 146.8097Epoch 00041: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 146.8180 - val_loss: 149.7862\n",
      "Epoch 43/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 146.7050Epoch 00042: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 146.7247 - val_loss: 149.8880\n",
      "Epoch 44/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 146.6358Epoch 00043: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 146.6259 - val_loss: 149.9039\n",
      "Epoch 45/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 146.5725Epoch 00044: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 146.5634 - val_loss: 149.6315\n",
      "Epoch 46/50\n",
      "59850/60000 [============================>.] - ETA: 0s - loss: 146.4548Epoch 00045: val_loss did not improve\n",
      "60000/60000 [==============================] - 16s - loss: 146.4604 - val_loss: 149.8019\n",
      "Epoch 47/50\n",
      "59950/60000 [============================>.] - ETA: 0s - loss: 146.3759Epoch 00046: val_loss improved from 149.61108 to 149.56960, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 146.3634 - val_loss: 149.5696\n",
      "Epoch 48/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 146.2896Epoch 00047: val_loss improved from 149.56960 to 149.54975, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 16s - loss: 146.2893 - val_loss: 149.5498\n",
      "Epoch 49/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 146.1865Epoch 00048: val_loss improved from 149.54975 to 149.37464, saving model to saved_models/Ezzat/weights.best.mnist.vae_2Layers\n",
      "60000/60000 [==============================] - 17s - loss: 146.1794 - val_loss: 149.3746\n",
      "Epoch 50/50\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 146.0924Epoch 00049: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 146.0993 - val_loss: 149.5019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1208a8ed0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path='saved_models/Ezzat/weights.best.mnist.'+'vae_'+'2Layers'\n",
    "print Path\n",
    "checkpoint=ModelCheckpoint(filepath=Path, \n",
    "                               verbose=1, save_best_only=True)\n",
    "vae.fit(x_train, x_train, validation_data=(x_test, x_test),\n",
    "                shuffle=True,  callbacks=[checkpoint], verbose=1, batch_size=50, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.load(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
